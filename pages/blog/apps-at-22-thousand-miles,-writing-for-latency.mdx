export const intro = `In my current role, I have had to write lots of web applications that run over satellite internet. 
Satellites in geostationary orbit have roughly a minimum of 500ms of latency. Typically, users notice latency after 120ms.
Despite the challenges that high latency provides, it is still possible to create applications that provide delightful user
experiences. Many of these patterns make sense outside high latency environments too. Here's how you can do it.`;

export const date = "7/29/2020";

## Apps at 22 Thousand Miles Away, Writing for High Latency

<p>{intro}</p>

### What is Latency?

At one point, the late senator Ted Stevens described the internet as a
[series of tubes](https://knowyourmeme.com/memes/series-of-tubes). While maybe
naive, it is an analogy that can be leveraged. Often the most important internet
connectivity elements are speed, bandwidth, and latency. Say these tubes had
water flowing though them. Speed is pretty self explanatory, it's how fast the
water goes through the pipe. Bandwidth is how wide the pipe is, faster speeds at
higher bandwidths mean more water can make it through. Now say the water only
goes through the tube when a faucet is turned on. The amount of time between
turning the facet and water coming out: that's latency.

There's lots of causes for latency in a computer application. The primary one
being how physically far you are from what you're trying to connect to. Any
signal is limited by the laws of physics and nothing seems to move faster than
the speed of light. Because of this you could have the most expensive fiber
optic cable that money can buy and if you're trying to connect to something on
the opposite end of the world, you'll still see latency.

Often, when writing applications we make use of distributed systems. This
website for example is hosted on a CDN, aka a content delivery network. Content
delivery networks create global edge nodes that are geographically closer to
customers. If you're in California, you'd connect to a server there or close to
there whereas in Europe you would instead connect to one likely in Europe.
There's lots of reasons to distribute a system too related to redundancy and
scale. However, in addition to the usual challenge. All of the traffic I've had
to write applications for has had to go through a satellite in geostationary
orbit.

### Why can Latency be high?

As stated before, signals can not go faster than the speed of light (though if
you can do this, I would love to take you out to lunch). When a network request
is made to a server far away, or through a satellite in geostationary orbit, the
signal has to physically travel there. Then, it will have to travel back. In the
case of the satellite, it has to go all the way back down to earth. For any
network request, it looks something like this:

1. Client to satellite => 22k miles
2. Satellite to ground station => 22k miles
3. Ground station to internet destination => Small amount of latency
4. Internet destination to ground station => Small amount of latency
5. Ground station back to satellite => 22k miles
6. Satellite back to client => 22k miles

That is at a minimum 88k miles that the signals travel. With the speed of light
taken into account it comes out to nearly 500ms of latency minimum plus whatever
latency it takes to actually reach the destination on the internet. While
satellite internet is an extreme case of this, many LTE networks also suffer
from some level of latency be it due to network setup or distance to a tower.

None of this is even taking into account additional time that may need to be
taken in regards to DNS and TCP.

### How can we fix it?

It's simple: ~~we kill the Batman~~ Minimize the number of hops done over the
network. As a developer, we unfortunately can not change a user's minimum
latency if the problem is on the supply side, so we need to construct our apps
accordingly.

There's a few techniques one can do to do this:

- Progressive rendering
- Rethinking images
- Cutting down on remote scripts
- API n+1 prevention

### Progressive Rendering

In my opinion, progressive rendering is by far the most useful thing one can do
to make their web app seem snappy on even the worst of network conditions. With
progressive rendering you render something in your HTML prior the the JavaScript
loading so that the user sees something. Typically, when websites are loaded,
the first thing returned is the HTML. The HTML then makes some reference to that
addition JavaScript needs to be loaded. The JavaScript is then loaded over an
additional network request and loaded by your browser. The time for JavaScript
code to load is enough of a problem and maybe even deserving of
[folks fat shaming bundle sizes on twitter](https://twitter.com/slightlylate).

To make something appear on the screen prior to the JavaScript loading, one can
use one of several tools. My favorite, which this website is built off is is
[Next.js](https://nextjs.org/); another popular tool is called
[Gatsby](https://www.gatsbyjs.org/). Each of these have a feature that allows
for something called _static site generation_. This allows for all of the html
pages to be created at build time, which is fantastic if the content is not
dynamic. This works great for things like blogs and ecommerce sites. However,
some JS may need to load regardless. At this point, one can put some sort of css
driven animation to signify that there's loading being done to at least give the
user some sort of semblance that something is happening.
[Next.js does this through a function called `getStaticProps`](https://nextjs.org/docs/basic-features/data-fetching#getstaticprops-static-generation)
whereas anything that Gatsby will be statically generated.

It is a fact of life that web apps may need some JavaScript in order to run
properly. There's some strategies one can take take to cut down on what
JavaScript is needed. The most popular is a technique called bundle splitting.
When you split your bundle, there's several JavaScript bundles that get
generated as opposed to one. Only when things from that bundle are needed does
it get loaded. Typically, this is managed on a per webpage level. The first
render has the unique JavaScript needed for itself as well as any common
JavaScript used on all pages. Subsequent page loads do not need to load that
common js again. Often these are pretty sophisticated and can even recognize if
js is needed on several, but not all pages and will only make one These days,
lots of tools give you this for "free." However as with many things, it needs to
be done properly.

... UNFINISHED ...
